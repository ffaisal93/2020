{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_ner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1GGnVGxlMG7_zfiUsxDCV8eiCAJ1kbmSr",
      "authorship_tag": "ABX9TyPDGdUD8LWt+Lu81TJSVF+Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ffaisal93/2020/blob/master/run_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0To4pzSKs8LU",
        "outputId": "80f5ce34-9b73-47c9-a53c-d0268aa73729"
      },
      "source": [
        "cd /content/drive/MyDrive/Colab_Notebooks"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wBHrzrisSka",
        "outputId": "71573f14-5686-49cb-f7d3-5b6245d9e946"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 84518, done.\u001b[K\n",
            "remote: Total 84518 (delta 0), reused 0 (delta 0), pack-reused 84518\u001b[K\n",
            "Receiving objects: 100% (84518/84518), 67.35 MiB | 6.63 MiB/s, done.\n",
            "Resolving deltas: 100% (60745/60745), done.\n",
            "Checking out files: 100% (1543/1543), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-_GJijds-k7",
        "outputId": "2d60fc72-891c-4077-c599-26d135c3ca90"
      },
      "source": [
        "cd transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94RHhoictQdI",
        "outputId": "f1db83a5-dfac-4b58-ff0c-037185e10229"
      },
      "source": [
        "!pip install ."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/Colab_Notebooks/transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0.dev0) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0.dev0) (4.62.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0.dev0) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 52.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0.dev0) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0.dev0) (3.0.12)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0.dev0) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.11.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.11.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0.dev0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.11.0.dev0-py3-none-any.whl size=2833295 sha256=cad0ad27a438d936e82f90aed0e000640c1f966393d846ecbebbf26fcade7f72\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5e6w_xq3/wheels/4e/d6/0c/98a384383e330ace37490f5f42c7c792e22a3ded4af2386180\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.11.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChxZnMCYtSbP",
        "outputId": "de257361-916f-476b-f1ad-534f59fd2137"
      },
      "source": [
        "!pip install -r ./examples/pytorch/token-classification/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.4.0-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 30 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 40 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting datasets>=1.8.0\n",
            "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 17.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from -r ./examples/pytorch/token-classification/requirements.txt (line 4)) (1.9.0+cu102)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (0.0.17)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (0.3.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (4.62.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (21.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (4.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (1.1.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (0.70.12.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 41.2 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->-r ./examples/pytorch/token-classification/requirements.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate->-r ./examples/pytorch/token-classification/requirements.txt (line 1)) (5.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->-r ./examples/pytorch/token-classification/requirements.txt (line 2)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r ./examples/pytorch/token-classification/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->-r ./examples/pytorch/token-classification/requirements.txt (line 2)) (1.0.1)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 50.7 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r ./examples/pytorch/token-classification/requirements.txt (line 3)) (1.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=6625f0a428ca02c9ab5745d528244aed4eb21c3afdcba79d19a8ac57dca52237\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, xxhash, seqeval, datasets, accelerate\n",
            "Successfully installed accelerate-0.4.0 aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.12.1 fsspec-2021.8.1 multidict-5.1.0 seqeval-1.2.2 xxhash-2.0.2 yarl-1.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJLKacXRtZPV",
        "outputId": "fb2f96b2-c3c8-454e-ec38-7f4585460d61"
      },
      "source": [
        "cd /content/drive/My Drive/Colab_Notebooks/transformers/examples/pytorch/token-classification"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab_Notebooks/transformers/examples/pytorch/token-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hTPNPTJOt5KJ",
        "outputId": "43df3079-0705-44df-eda5-08cf4bb98056"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab_Notebooks/transformers/examples/pytorch/token-classification'"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCa2xTLPt6Kl",
        "outputId": "6330d04f-9145-47b9-bf43-fda54e65e24f"
      },
      "source": [
        "ls"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md         run_ner_no_trainer.py  run_no_trainer.sh\n",
            "requirements.txt  run_ner.py             run.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqp9DGiOM3vX"
      },
      "source": [
        "MAX_LENGTH = 128 #@param {type: \"integer\"}\n",
        "MODEL = \"/content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1\" #@param [\"/content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1\", \"bert-base-multilingual-cased\"]\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab_Notebooks/models/ner_temp\" #@param [\"/content/drive/MyDrive/Colab_Notebooks/models/ner_temp\"]\n",
        "BATCH_SIZE = 32 #@param {type: \"integer\"}\n",
        "NUM_EPOCHS = 3 #@param {type: \"integer\"}\n",
        "SAVE_STEPS = 100 #@param {type: \"integer\"}\n",
        "LOGGING_STEPS = 100 #@param {type: \"integer\"}\n",
        "SEED = 42 #@param {type: \"integer\"}"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxaMpecQUJ9b",
        "outputId": "506d7f1c-03ee-454b-b614-7ef768993bd2"
      },
      "source": [
        "!python3 run_ner.py \\\n",
        "  --dataset_name conllpp \\\n",
        "  --model_name_or_path $MODEL \\\n",
        "  --output_dir $OUTPUT_DIR \\\n",
        "  --max_seq_length  $MAX_LENGTH \\\n",
        "  --num_train_epochs $NUM_EPOCHS \\\n",
        "  --per_device_train_batch_size $BATCH_SIZE \\\n",
        "  --save_steps $SAVE_STEPS \\\n",
        "  --logging_steps $LOGGING_STEPS \\\n",
        "  --seed $SEED \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_predict \\\n",
        "  --overwrite_output_dir"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "09/18/2021 05:13:15 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "09/18/2021 05:13:15 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=None,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/Colab_Notebooks/models/ner_temp/runs/Sep18_05-13-15_bceb66cbd1a2,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=100,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=/content/drive/MyDrive/Colab_Notebooks/models/ner_temp,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/Colab_Notebooks/models/ner_temp,\n",
            "save_on_each_node=False,\n",
            "save_steps=100,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "09/18/2021 05:13:15 - INFO - datasets.load - Found main folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/conllpp/conllpp.py at /root/.cache/huggingface/modules/datasets_modules/datasets/conllpp\n",
            "09/18/2021 05:13:15 - INFO - datasets.load - Found specific version folder for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/conllpp/conllpp.py at /root/.cache/huggingface/modules/datasets_modules/datasets/conllpp/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2\n",
            "09/18/2021 05:13:15 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/conllpp/conllpp.py to /root/.cache/huggingface/modules/datasets_modules/datasets/conllpp/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2/conllpp.py\n",
            "09/18/2021 05:13:15 - INFO - datasets.load - Found dataset infos file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/conllpp/dataset_infos.json to /root/.cache/huggingface/modules/datasets_modules/datasets/conllpp/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2/dataset_infos.json\n",
            "09/18/2021 05:13:15 - INFO - datasets.load - Found metadata file for dataset https://raw.githubusercontent.com/huggingface/datasets/1.12.1/datasets/conllpp/conllpp.py at /root/.cache/huggingface/modules/datasets_modules/datasets/conllpp/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2/conllpp.json\n",
            "09/18/2021 05:13:15 - INFO - datasets.builder - No config specified, defaulting to first: conllpp/conllpp\n",
            "09/18/2021 05:13:15 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/conllpp/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2\n",
            "09/18/2021 05:13:15 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
            "09/18/2021 05:13:15 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2\n",
            "09/18/2021 05:13:15 - WARNING - datasets.builder - Reusing dataset conllpp (/root/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2)\n",
            "09/18/2021 05:13:15 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2\n",
            "100% 3/3 [00:00<00:00, 459.82it/s]\n",
            "[INFO|configuration_utils.py:572] 2021-09-18 05:13:15,676 >> loading configuration file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/config.json\n",
            "[INFO|configuration_utils.py:611] 2021-09-18 05:13:15,701 >> Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2,\n",
            "    \"3\": 3,\n",
            "    \"4\": 4,\n",
            "    \"5\": 5,\n",
            "    \"6\": 6,\n",
            "    \"7\": 7,\n",
            "    \"8\": 8\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2,\n",
            "    \"3\": 3,\n",
            "    \"4\": 4,\n",
            "    \"5\": 5,\n",
            "    \"6\": 6,\n",
            "    \"7\": 7,\n",
            "    \"8\": 8\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.11.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:333] 2021-09-18 05:13:15,702 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:572] 2021-09-18 05:13:15,704 >> loading configuration file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/config.json\n",
            "[INFO|configuration_utils.py:611] 2021-09-18 05:13:15,704 >> Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.11.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-09-18 05:13:15,707 >> Didn't find file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-09-18 05:13:15,707 >> Didn't find file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-09-18 05:13:15,708 >> Didn't find file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/special_tokens_map.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-09-18 05:13:15,709 >> Didn't find file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/tokenizer_config.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-18 05:13:15,709 >> loading file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-18 05:13:15,709 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-18 05:13:15,709 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-18 05:13:15,709 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-18 05:13:15,709 >> loading file None\n",
            "[INFO|configuration_utils.py:572] 2021-09-18 05:13:15,711 >> loading configuration file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/config.json\n",
            "[INFO|configuration_utils.py:611] 2021-09-18 05:13:15,711 >> Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.11.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:572] 2021-09-18 05:13:15,858 >> loading configuration file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/config.json\n",
            "[INFO|configuration_utils.py:611] 2021-09-18 05:13:15,859 >> Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.11.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1289] 2021-09-18 05:13:15,940 >> loading weights file /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1547] 2021-09-18 05:13:35,989 >> All model checkpoint weights were used when initializing BertForTokenClassification.\n",
            "\n",
            "[WARNING|modeling_utils.py:1550] 2021-09-18 05:13:35,989 >> Some weights of BertForTokenClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Colab_Notebooks/models/pytorch_mbert_100lang_1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "09/18/2021 05:13:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2/cache-61a9fc90b113a022.arrow\n",
            "Running tokenizer on validation dataset:   0% 0/4 [00:00<?, ?ba/s]09/18/2021 05:13:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2/cache-f8f7b51c6917bdd7.arrow\n",
            "Running tokenizer on validation dataset: 100% 4/4 [00:00<00:00,  5.27ba/s]\n",
            "09/18/2021 05:13:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/conllpp/conllpp/1.0.0/04f15f257dff3fe0fb36e049b73d51ecdf382698682f5e590b7fb13898206ba2/cache-672662d72e55a8da.arrow\n",
            "09/18/2021 05:13:37 - INFO - datasets.load - Found main folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.12.1/metrics/seqeval/seqeval.py at /root/.cache/huggingface/modules/datasets_modules/metrics/seqeval\n",
            "09/18/2021 05:13:37 - INFO - datasets.load - Found specific version folder for metric https://raw.githubusercontent.com/huggingface/datasets/1.12.1/metrics/seqeval/seqeval.py at /root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/1fde2544ac1f3f7e54c639c73221d3a5e5377d2213b9b0fdb579b96980b84b2e\n",
            "09/18/2021 05:13:37 - INFO - datasets.load - Found script file from https://raw.githubusercontent.com/huggingface/datasets/1.12.1/metrics/seqeval/seqeval.py to /root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/1fde2544ac1f3f7e54c639c73221d3a5e5377d2213b9b0fdb579b96980b84b2e/seqeval.py\n",
            "09/18/2021 05:13:37 - INFO - datasets.load - Couldn't find dataset infos file at https://raw.githubusercontent.com/huggingface/datasets/1.12.1/metrics/seqeval/dataset_infos.json\n",
            "09/18/2021 05:13:37 - INFO - datasets.load - Found metadata file for metric https://raw.githubusercontent.com/huggingface/datasets/1.12.1/metrics/seqeval/seqeval.py at /root/.cache/huggingface/modules/datasets_modules/metrics/seqeval/1fde2544ac1f3f7e54c639c73221d3a5e5377d2213b9b0fdb579b96980b84b2e/seqeval.json\n",
            "[INFO|trainer.py:539] 2021-09-18 05:13:40,163 >> The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags, chunk_tags, pos_tags, id.\n",
            "[WARNING|training_args.py:859] 2021-09-18 05:13:40,172 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[WARNING|training_args.py:859] 2021-09-18 05:13:40,172 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "[INFO|trainer.py:1186] 2021-09-18 05:13:40,185 >> ***** Running training *****\n",
            "[INFO|trainer.py:1187] 2021-09-18 05:13:40,185 >>   Num examples = 14041\n",
            "[INFO|trainer.py:1188] 2021-09-18 05:13:40,185 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1189] 2021-09-18 05:13:40,185 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1190] 2021-09-18 05:13:40,185 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:1191] 2021-09-18 05:13:40,186 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1192] 2021-09-18 05:13:40,186 >>   Total optimization steps = 1317\n",
            "[WARNING|training_args.py:859] 2021-09-18 05:13:40,198 >> Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
            "{'loss': 0.2831, 'learning_rate': 4.62034927866363e-05, 'epoch': 0.23}\n",
            "  8% 100/1317 [01:08<13:36,  1.49it/s][INFO|trainer.py:1963] 2021-09-18 05:14:48,623 >> Saving model checkpoint to /content/drive/MyDrive/Colab_Notebooks/models/ner_temp/checkpoint-100\n",
            "[INFO|configuration_utils.py:404] 2021-09-18 05:14:48,633 >> Configuration saved in /content/drive/MyDrive/Colab_Notebooks/models/ner_temp/checkpoint-100/config.json\n",
            "[INFO|modeling_utils.py:1013] 2021-09-18 05:14:52,634 >> Model weights saved in /content/drive/MyDrive/Colab_Notebooks/models/ner_temp/checkpoint-100/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2033] 2021-09-18 05:14:52,646 >> tokenizer config file saved in /content/drive/MyDrive/Colab_Notebooks/models/ner_temp/checkpoint-100/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2039] 2021-09-18 05:14:52,652 >> Special tokens file saved in /content/drive/MyDrive/Colab_Notebooks/models/ner_temp/checkpoint-100/special_tokens_map.json\n",
            " 10% 129/1317 [01:50<12:56,  1.53it/s]Traceback (most recent call last):\n",
            "  File \"run_ner.py\", line 564, in <module>\n",
            "    main()\n",
            "  File \"run_ner.py\", line 497, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1304, in train\n",
            "    if args.logging_nan_inf_filter and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step)):\n",
            "KeyboardInterrupt\n",
            " 10% 129/1317 [01:51<17:03,  1.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRxC3vGRUaGg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}